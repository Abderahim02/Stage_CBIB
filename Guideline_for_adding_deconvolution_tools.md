## General steps
1) Create a new folder in `subworkflows/deconvolution`, containing
   - A script which (minimally) takes as **input** a single-cell reference matrix, spatial expression matrix, and cell type annotation column, <br> 
and returns as **output** a TSV file of the predicted proportions (spots in rows and cell types in columns)
   - A Nextflow process which calls this script
  
2) Include the process in `subworkflows/deconvolution/run_methods.nf`

### Example: implementing NNLS in R
We will be adding a simple algorithm of non-negative least squares regression to the pipeline. For R methods, we assume the single-cell reference is a Seurat Object with a cell type annotation column, and the
spatial object is either a Seurat object or a synthetic dataset generated by synthvisium (a named list with the expression matrix in "counts").

1. Create a directory `subworkflows/deconvolution/nnls` containing
   - `script_nf.R`: a script that runs NNLS. We use `R.utils::commandArgs` to parse command line arguments, with `sc_input` and `sp_input` the path to the single-cell and spatial objects, and `annot` the name of the cell type annotation column.
   <br>The script returns a TSV file of the spot x cell type proportion matrix. We recommend copying the template of results printing, <br>because we 1) do not include rownames, 2) remove non-alphanumeric characters from cell types and 3) shell sort the cell types. 
   - `run_method.nf`: a Nextflow process that runs `script_nf.R`. For simple cases you can simply replace "nnls" with your method name. You can remove the `container` directive if you only wish to run it locally.
   - **OPTIONAL:** build a docker container with your method (see `Dockerfile`)
2. Add nnls to subworkflows/deconvolution/run_methods.nf
   - In the `include` statement at the beginning of the file (`include { runNNLS } from './nnls/run_method.nf'`)
   - In parameters `all_methods` (`all_methods = "music,rctd, ... ,dstg,nnls"`)
   - In the  `runMethods` workflow
    ```
        if ( methods =~ /nnls/ ){
            runNNLS(pair_input_ch)
            output_ch = output_ch.mix(runNNLS.out)
        }
    ```
  
3. Test it out with
```
nextflow run main.nf --methods nnls -profile local \
--sc_input unit-test/test_sc_data.rds --sp_input unit-test/test_sp_data.rds \
--annot subclass 
```


======== EXTRA INFORMATION FOR PYTHON METHODS =========
For NNLS the workflow is exactly the same, but we expect the input to be h5ad files instaed of Seurat objects.
Nonetheless, most Python methods include model building and training, so you would need two files to do so.
Typically, the model building only takes the single-cell h5ad file as input along with the annotation column, while the model fitting takes the trained model along with the spatial dataset.
When running a benchmark, we sometimes have 10 spatial datasets for 1 single-cell dataset. To save time, we will only build the model once and use it for all spatial datasets. Hence, the model output channel has to be replicated. Let's break down the code of cell2location


buildCell2locationModel(sc_input_pair)					--> build model using only single-cell dataset

// Repeat model output for each spatial file
buildCell2locationModel.out.combine(sp_input_pair)			--> .out is the model, copy the model for each spatial dataset there is
.multiMap { model_sc_file, sp_file_h5ad, sp_file_rds ->			--> we have the model file, and two spatial files (h5ad and original Seurat object)
            model: model_sc_file					--> the model file is now called "model"
            sp_input: tuple sp_file_h5ad, sp_file_rds }			--> the spatial files are grouped as a tuple, accessed via "sp_input)
.set{ c2l_combined_ch }							--> the new variable is now named c2l_combined_ch

fitCell2locationModel(c2l_combined_ch.sp_input,				--> fit the model using sp_input tuple
                      c2l_combined_ch.model)				--> and the model file
formatC2L(fitCell2locationModel.out)					--> format the TSV file outputted by the cell2location model
output_ch = output_ch.mix(formatC2L.out)

The reason we need to use multiMap to reformat the sp_input as a tuple is to match the input we defined in fitCell2locationModel (in run_method.nf)
input:
	tuple path (sp_input), path (sp_input_rds)
	path (model)
Note that we always pass the sp_input_rds file because we need it downstream for metrics computation.
